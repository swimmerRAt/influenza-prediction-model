#!/usr/bin/env python3
"""
ë°ì´í„° í•„í„°ë§ ë¬´ê²°ì„± ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
- ì—°ë ¹ë³„/ì•„í˜•ë³„ í•„í„°ë§ ê³¼ì •ì—ì„œ ë°ì´í„° ì†ìƒ ì—¬ë¶€ í™•ì¸
"""

import sys
import pandas as pd
import numpy as np
from pathlib import Path

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).parent
DATA_DIR = BASE_DIR / "data" / "before"

# patchTST.pyì—ì„œ í•„ìš”í•œ í•¨ìˆ˜ë“¤ ì„í¬íŠ¸
from patchTST import (
    load_raw_data_by_age_group,
    load_subtype_data,
    get_available_age_groups,
    AGE_GROUP_MAPPING,
)


def load_all_raw_csvs():
    """ëª¨ë“  ì›ë³¸ CSV íŒŒì¼ì„ ë¡œë“œí•˜ì—¬ í†µê³„ ê³„ì‚°"""
    all_data = {}
    
    datasets = {
        'ds_0101': 'ì˜ì‚¬í™˜ì ë¶„ìœ¨',
        'ds_0103': 'ì…ì›í™˜ì ìˆ˜',
        'ds_0104': 'ì…ì›í™˜ì ìˆ˜',
        'ds_0106': 'ì¸í”Œë£¨ì—”ì ê²€ì¶œë¥ ',
        'ds_0107': 'ê²€ì¶œë¥ ',  # ì•„í˜•ë³„
        'ds_0108': 'ì¸í”Œë£¨ì—”ì ê²€ì¶œë¥ ',
        'ds_0109': 'ì‘ê¸‰ì‹¤ ì¸í”Œë£¨ì—”ì í™˜ì',
        'ds_0110': 'ì˜ˆë°©ì ‘ì¢…ë¥ ',
    }
    
    for dsid, col_name in datasets.items():
        ds_num = dsid.replace('ds_', '')
        pattern = f"flu-{ds_num}-*.csv"
        files = list(DATA_DIR.glob(pattern))
        
        if not files:
            continue
        
        dfs = []
        for f in sorted(files):
            try:
                df = pd.read_csv(f)
                dfs.append(df)
            except Exception as e:
                print(f"   âš ï¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ ({f.name}): {e}")
        
        if dfs:
            df_combined = pd.concat(dfs, ignore_index=True)
            all_data[dsid] = df_combined
    
    return all_data


def validate_age_filtering():
    """ì—°ë ¹ë³„ í•„í„°ë§ ê²€ì¦"""
    print("\n" + "=" * 70)
    print("ğŸ” ì—°ë ¹ë³„ í•„í„°ë§ ê²€ì¦")
    print("=" * 70)
    
    # ì›ë³¸ ë°ì´í„° ë¡œë“œ
    raw_data = load_all_raw_csvs()
    
    # ì‚¬ìš© ê°€ëŠ¥í•œ ì—°ë ¹ëŒ€ í™•ì¸
    age_info = get_available_age_groups(str(DATA_DIR))
    
    print("\nğŸ“Š ì›ë³¸ ë°ì´í„°ì…‹ë³„ í†µê³„:")
    for dsid, df in raw_data.items():
        print(f"\n   {dsid}:")
        print(f"      - ì´ í–‰ ìˆ˜: {len(df)}")
        if 'ì—°ë ¹ëŒ€' in df.columns:
            age_groups = df['ì—°ë ¹ëŒ€'].dropna().unique()
            print(f"      - ì—°ë ¹ëŒ€ ì¢…ë¥˜: {len(age_groups)}ê°œ")
            print(f"      - ì—°ë ¹ëŒ€ ëª©ë¡: {sorted([str(a) for a in age_groups])}")
    
    # ê° ì—°ë ¹ëŒ€ë³„ë¡œ í•„í„°ë§ í…ŒìŠ¤íŠ¸
    test_ages = ['0-6ì„¸', '7-12ì„¸', '13-18ì„¸', '19-49ì„¸', '50-64ì„¸', '65ì„¸ì´ìƒ']
    
    print("\nğŸ“Š ì—°ë ¹ëŒ€ë³„ í•„í„°ë§ ê²°ê³¼:")
    results = []
    
    for age in test_ages:
        print(f"\n   ğŸ”¸ ì—°ë ¹ëŒ€: {age}")
        try:
            df_filtered = load_raw_data_by_age_group(data_dir=str(DATA_DIR), age_group=age)
            
            if df_filtered.empty:
                print(f"      âŒ ë°ì´í„° ì—†ìŒ")
                results.append({'age': age, 'rows': 0, 'status': 'EMPTY'})
                continue
            
            # ê¸°ë³¸ í†µê³„
            row_count = len(df_filtered)
            col_count = len(df_filtered.columns)
            
            # ê²°ì¸¡ì¹˜ í™•ì¸
            null_counts = df_filtered.isnull().sum()
            null_total = null_counts.sum()
            
            # ILI ë²”ìœ„ í™•ì¸
            ili_min = df_filtered['ili'].min() if 'ili' in df_filtered.columns else None
            ili_max = df_filtered['ili'].max() if 'ili' in df_filtered.columns else None
            
            # ì—°ë„/ì£¼ì°¨ ë²”ìœ„
            year_min = df_filtered['year'].min()
            year_max = df_filtered['year'].max()
            week_range = (df_filtered['week'].min(), df_filtered['week'].max())
            
            print(f"      - í–‰ ìˆ˜: {row_count}")
            print(f"      - ì»¬ëŸ¼ ìˆ˜: {col_count}")
            print(f"      - ì»¬ëŸ¼: {list(df_filtered.columns)}")
            print(f"      - ê²°ì¸¡ì¹˜ ì´í•©: {null_total}")
            if null_total > 0:
                print(f"      - ê²°ì¸¡ì¹˜ ìƒì„¸: {dict(null_counts[null_counts > 0])}")
            print(f"      - ì—°ë„ ë²”ìœ„: {year_min} ~ {year_max}")
            print(f"      - ì£¼ì°¨ ë²”ìœ„: {week_range[0]} ~ {week_range[1]}")
            if ili_min is not None:
                print(f"      - ILI ë²”ìœ„: {ili_min:.2f} ~ {ili_max:.2f}")
            
            # ì‹œê°„ìˆœ ì •ë ¬ í™•ì¸
            is_sorted = df_filtered['year'].is_monotonic_increasing or (
                df_filtered.sort_values(['year', 'week']).index.tolist() == df_filtered.index.tolist()
            )
            print(f"      - ì‹œê°„ìˆœ ì •ë ¬: {'âœ… OK' if is_sorted else 'âŒ ì •ë ¬ í•„ìš”'}")
            
            # ì¤‘ë³µ í™•ì¸
            duplicates = df_filtered.duplicated(subset=['year', 'week']).sum()
            print(f"      - ì¤‘ë³µ í–‰: {duplicates}ê°œ")
            
            results.append({
                'age': age, 
                'rows': row_count, 
                'nulls': null_total,
                'duplicates': duplicates,
                'status': 'OK' if null_total == 0 and duplicates == 0 else 'WARNING'
            })
            
        except Exception as e:
            print(f"      âŒ ì˜¤ë¥˜: {e}")
            results.append({'age': age, 'rows': 0, 'status': f'ERROR: {e}'})
    
    return results


def validate_subtype_filtering():
    """ì•„í˜•ë³„ í•„í„°ë§ ê²€ì¦"""
    print("\n" + "=" * 70)
    print("ğŸ” ì•„í˜•ë³„ í•„í„°ë§ ê²€ì¦")
    print("=" * 70)
    
    # ì›ë³¸ ds_0107 ë°ì´í„° í™•ì¸
    ds_0107_files = list(DATA_DIR.glob("flu-0107-*.csv"))
    
    if not ds_0107_files:
        print("\n   âš ï¸ ds_0107 íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    # ì›ë³¸ ë°ì´í„° ë¡œë“œ
    dfs = []
    for f in sorted(ds_0107_files):
        try:
            df = pd.read_csv(f)
            dfs.append(df)
        except Exception as e:
            print(f"   âš ï¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ ({f.name}): {e}")
    
    if not dfs:
        print("\n   âš ï¸ ds_0107 ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    df_raw = pd.concat(dfs, ignore_index=True)
    
    print(f"\nğŸ“Š ì›ë³¸ ds_0107 ë°ì´í„°:")
    print(f"   - ì´ í–‰ ìˆ˜: {len(df_raw)}")
    print(f"   - ì»¬ëŸ¼: {list(df_raw.columns)}")
    
    # ì•„í˜• ì»¬ëŸ¼ ì°¾ê¸°
    subtype_col = None
    for col in ['ì•„í˜•', 'subtype', 'ì¸í”Œë£¨ì—”ììœ í˜•']:
        if col in df_raw.columns:
            subtype_col = col
            break
    
    if subtype_col:
        subtypes = df_raw[subtype_col].unique()
        print(f"   - ì•„í˜• ì»¬ëŸ¼: {subtype_col}")
        print(f"   - ì•„í˜• ì¢…ë¥˜: {subtypes}")
        
        for st in subtypes:
            count = len(df_raw[df_raw[subtype_col] == st])
            print(f"      - {st}: {count}í–‰")
    
    # í•„í„°ë§ í…ŒìŠ¤íŠ¸
    print("\nğŸ“Š ì•„í˜•ë³„ í•„í„°ë§ ê²°ê³¼:")
    results = []
    
    for subtype in ['A', 'B', 'all']:
        print(f"\n   ğŸ”¸ ì•„í˜•: {subtype}")
        try:
            df_filtered = load_subtype_data(data_dir=str(DATA_DIR), subtype=subtype)
            
            if df_filtered.empty:
                print(f"      âŒ ë°ì´í„° ì—†ìŒ")
                results.append({'subtype': subtype, 'rows': 0, 'status': 'EMPTY'})
                continue
            
            row_count = len(df_filtered)
            col_count = len(df_filtered.columns)
            
            # ê²°ì¸¡ì¹˜ í™•ì¸
            null_counts = df_filtered.isnull().sum()
            null_total = null_counts.sum()
            
            print(f"      - í–‰ ìˆ˜: {row_count}")
            print(f"      - ì»¬ëŸ¼: {list(df_filtered.columns)}")
            print(f"      - ê²°ì¸¡ì¹˜: {null_total}")
            
            # ê²€ì¶œë¥  ë²”ìœ„
            if 'detection_rate' in df_filtered.columns:
                dr_min = df_filtered['detection_rate'].min()
                dr_max = df_filtered['detection_rate'].max()
                print(f"      - ê²€ì¶œë¥  ë²”ìœ„: {dr_min:.2f} ~ {dr_max:.2f}")
            
            # ì—°ë„/ì£¼ì°¨ ë²”ìœ„
            if 'year' in df_filtered.columns:
                print(f"      - ì—°ë„ ë²”ìœ„: {df_filtered['year'].min()} ~ {df_filtered['year'].max()}")
            
            results.append({
                'subtype': subtype, 
                'rows': row_count, 
                'nulls': null_total,
                'status': 'OK' if null_total == 0 else 'WARNING'
            })
            
        except Exception as e:
            print(f"      âŒ ì˜¤ë¥˜: {e}")
            results.append({'subtype': subtype, 'rows': 0, 'status': f'ERROR: {e}'})
    
    return results


def validate_data_consistency():
    """ë°ì´í„° ì¼ê´€ì„± ê²€ì¦: í•„í„°ë§ ì „í›„ í•©ê³„ ë¹„êµ"""
    print("\n" + "=" * 70)
    print("ğŸ” ë°ì´í„° ì¼ê´€ì„± ê²€ì¦ (í•„í„°ë§ ì „í›„ ë¹„êµ)")
    print("=" * 70)
    
    # ds_0101 (ILI) ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
    ds_0101_files = list(DATA_DIR.glob("flu-0101-*.csv"))
    
    if not ds_0101_files:
        print("\n   âš ï¸ ds_0101 íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì›ë³¸ ë¡œë“œ
    dfs = []
    for f in sorted(ds_0101_files):
        try:
            df = pd.read_csv(f)
            dfs.append(df)
        except Exception:
            pass
    
    if not dfs:
        return
    
    df_raw = pd.concat(dfs, ignore_index=True)
    
    print(f"\nğŸ“Š ì›ë³¸ ds_0101 ë°ì´í„°:")
    print(f"   - ì´ í–‰ ìˆ˜: {len(df_raw)}")
    
    if 'ì—°ë ¹ëŒ€' not in df_raw.columns:
        print("   âš ï¸ ì—°ë ¹ëŒ€ ì»¬ëŸ¼ ì—†ìŒ")
        return
    
    # ì—°ë ¹ëŒ€ë³„ í–‰ ìˆ˜ (ì›ë³¸)
    raw_age_counts = df_raw.groupby('ì—°ë ¹ëŒ€').size().to_dict()
    print(f"   - ì—°ë ¹ëŒ€ë³„ í–‰ ìˆ˜ (ì›ë³¸):")
    for age, count in sorted(raw_age_counts.items()):
        print(f"      - {age}: {count}")
    
    # í•„í„°ë§ í›„ í–‰ ìˆ˜ í•©ê³„
    test_ages = ['0ì„¸', '1-6ì„¸', '7-12ì„¸', '13-18ì„¸', '19-49ì„¸', '50-64ì„¸', '65ì„¸ì´ìƒ']
    filtered_total = 0
    
    print(f"\n   - í•„í„°ë§ í›„ í–‰ ìˆ˜:")
    for age in test_ages:
        try:
            df_filtered = load_raw_data_by_age_group(data_dir=str(DATA_DIR), age_group=age)
            filtered_total += len(df_filtered)
        except:
            pass
    
    # ì›ë³¸ ì—°ë ¹ëŒ€ í•©ê³„ (test_agesì— í•´ë‹¹í•˜ëŠ” ê²ƒë§Œ)
    raw_total = sum(raw_age_counts.get(age, 0) for age in test_ages)
    
    print(f"\nğŸ“Š ë¹„êµ ê²°ê³¼:")
    print(f"   - ì›ë³¸ ì´ í–‰ ìˆ˜ (ì£¼ìš” ì—°ë ¹ëŒ€): {raw_total}")
    print(f"   - í•„í„°ë§ í›„ ì´ í–‰ ìˆ˜: {filtered_total}")
    
    # ì£¼ì˜: í•„í„°ë§ í›„ì—ëŠ” year/week ê¸°ì¤€ìœ¼ë¡œ ë³‘í•©ë˜ë¯€ë¡œ í–‰ ìˆ˜ê°€ ì¤„ì–´ë“¦
    print(f"   - ì°¸ê³ : í•„í„°ë§ í•¨ìˆ˜ëŠ” ì—°ë„/ì£¼ì°¨ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë³‘í•©í•˜ë¯€ë¡œ")
    print(f"           í–‰ ìˆ˜ê°€ ì¤„ì–´ë“œëŠ” ê²ƒì€ ì •ìƒì…ë‹ˆë‹¤ (ë³‘í•© í›„ 436í–‰ ì˜ˆìƒ)")


def main():
    print("\n" + "ğŸ”¬ " * 20)
    print("ë°ì´í„° í•„í„°ë§ ë¬´ê²°ì„± ê²€ì¦ ì‹œì‘")
    print("ğŸ”¬ " * 20)
    
    # 1. ì—°ë ¹ë³„ í•„í„°ë§ ê²€ì¦
    age_results = validate_age_filtering()
    
    # 2. ì•„í˜•ë³„ í•„í„°ë§ ê²€ì¦
    subtype_results = validate_subtype_filtering()
    
    # 3. ë°ì´í„° ì¼ê´€ì„± ê²€ì¦
    validate_data_consistency()
    
    # ìµœì¢… ìš”ì•½
    print("\n" + "=" * 70)
    print("ğŸ“‹ ê²€ì¦ ìš”ì•½")
    print("=" * 70)
    
    print("\nì—°ë ¹ë³„ í•„í„°ë§:")
    for r in age_results:
        status_icon = "âœ…" if r.get('status') == 'OK' else ("âš ï¸" if 'WARNING' in str(r.get('status', '')) else "âŒ")
        print(f"   {status_icon} {r['age']}: {r['rows']}í–‰ - {r.get('status', 'UNKNOWN')}")
    
    print("\nì•„í˜•ë³„ í•„í„°ë§:")
    for r in subtype_results:
        status_icon = "âœ…" if r.get('status') == 'OK' else ("âš ï¸" if 'WARNING' in str(r.get('status', '')) else "âŒ")
        print(f"   {status_icon} {r['subtype']}: {r['rows']}í–‰ - {r.get('status', 'UNKNOWN')}")
    
    print("\n" + "=" * 70)
    print("âœ… ê²€ì¦ ì™„ë£Œ")
    print("=" * 70)


if __name__ == "__main__":
    main()

#!/usr/bin/env python3
"""
data/before í´ë”ì™€ merged_influenza_data.csv ë¹„êµ ìŠ¤í¬ë¦½íŠ¸

ë¹„êµ í•­ëª©:
1. ì›ë³¸ ë°ì´í„° í†µê³„ (íŒŒì¼ë³„ ë ˆì½”ë“œ ìˆ˜)
2. ë³‘í•© ë°ì´í„° í†µê³„
3. ì—°ë„/ì£¼ì°¨ë³„ ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ ë¹„êµ
4. ê°’ ì¼ì¹˜ ì—¬ë¶€ í™•ì¸
"""

import os
import pandas as pd
from pathlib import Path
from collections import defaultdict

# ë°ì´í„°ì…‹ ID â†’ ì»¬ëŸ¼ ë§¤í•‘
DATASET_COLUMN_MAPPING = {
    'ds_0101': {'value_col': 'ì˜ì‚¬í™˜ì ë¶„ìœ¨', 'merged_col': 'ili', 'group_col': 'ì—°ë ¹ëŒ€'},
    'ds_0103': {'value_col': 'ì…ì›í™˜ì ìˆ˜', 'merged_col': 'hospitalization', 'group_col': 'ì—°ë ¹ëŒ€'},
    'ds_0104': {'value_col': 'ì…ì›í™˜ì ìˆ˜', 'merged_col': 'hospitalization', 'group_col': 'ì—°ë ¹ëŒ€'},
    'ds_0105': {'value_col': 'ì¸í”Œë£¨ì—”ì ê²€ì¶œë¥ ', 'merged_col': 'detection_rate', 'group_col': 'ì•„í˜•'},
    'ds_0106': {'value_col': 'ì¸í”Œë£¨ì—”ì ê²€ì¶œë¥ ', 'merged_col': 'detection_rate', 'group_col': 'ì—°ë ¹ëŒ€'},
    'ds_0107': {'value_col': 'ê²€ì¶œë¥ ', 'merged_col': 'detection_rate', 'group_col': 'ì•„í˜•'},
    'ds_0108': {'value_col': 'ê²€ì¶œë¥ ', 'merged_col': 'detection_rate', 'group_col': 'ì—°ë ¹ëŒ€'},
    'ds_0109': {'value_col': 'í™˜ì ìˆ˜', 'merged_col': 'emergency_patients', 'group_col': 'ì—°ë ¹ëŒ€'},
    'ds_0110': {'value_col': 'ì ‘ì¢…ë¥ ', 'merged_col': 'vaccine_rate', 'group_col': 'ì—°ë ¹ëŒ€'},
}


def load_before_data(before_dir='data/before'):
    """
    data/before í´ë”ì˜ ëª¨ë“  CSV íŒŒì¼ ë¡œë“œ
    
    Returns:
        dict: {dsid: DataFrame}
    """
    before_path = Path(before_dir)
    if not before_path.exists():
        print(f"âŒ {before_dir} í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return {}
    
    csv_files = list(before_path.glob('*.csv'))
    print(f"\nğŸ“‚ {before_dir} í´ë”ì—ì„œ {len(csv_files)}ê°œ CSV íŒŒì¼ ë°œê²¬\n")
    
    # ë°ì´í„°ì…‹ë³„ë¡œ ê·¸ë£¹í™”
    dataset_files = defaultdict(list)
    for f in csv_files:
        # flu-0101-2017.csv â†’ ds_0101
        parts = f.stem.split('-')
        if len(parts) >= 2:
            dsid = f'ds_{parts[1]}'
            dataset_files[dsid].append(f)
    
    # ê° ë°ì´í„°ì…‹ë³„ë¡œ íŒŒì¼ ë¡œë“œ ë° ë³‘í•©
    all_data = {}
    for dsid, files in sorted(dataset_files.items()):
        dfs = []
        total_rows = 0
        for f in sorted(files):
            try:
                df = pd.read_csv(f, encoding='utf-8-sig')
                df['source_file'] = f.name
                df['dsid'] = dsid
                dfs.append(df)
                total_rows += len(df)
            except Exception as e:
                print(f"   âš ï¸  {f.name} ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        if dfs:
            combined = pd.concat(dfs, ignore_index=True)
            all_data[dsid] = combined
            print(f"   ğŸ“Š {dsid}: {len(files)}ê°œ íŒŒì¼, {total_rows}í–‰")
    
    return all_data


def load_merged_data(merged_path='merged_influenza_data.csv'):
    """
    merged_influenza_data.csv ë¡œë“œ
    """
    if not os.path.exists(merged_path):
        print(f"âŒ {merged_path} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return None
    
    df = pd.read_csv(merged_path)
    print(f"\nğŸ“Š ë³‘í•© ë°ì´í„°: {len(df)}í–‰, {len(df.columns)}ê°œ ì»¬ëŸ¼")
    print(f"   ì»¬ëŸ¼: {list(df.columns)}")
    return df


def compare_statistics(before_data, merged_df):
    """
    ê¸°ë³¸ í†µê³„ ë¹„êµ
    """
    print("\n" + "="*70)
    print("ğŸ“Š ê¸°ë³¸ í†µê³„ ë¹„êµ")
    print("="*70)
    
    # ì›ë³¸ ë°ì´í„° í†µê³„
    total_before = sum(len(df) for df in before_data.values())
    print(f"\n[ì›ë³¸ ë°ì´í„° (data/before)]")
    print(f"   â€¢ ì´ ë ˆì½”ë“œ ìˆ˜: {total_before:,}")
    print(f"   â€¢ ë°ì´í„°ì…‹ ìˆ˜: {len(before_data)}")
    
    for dsid, df in sorted(before_data.items()):
        print(f"     - {dsid}: {len(df):,}í–‰")
    
    # ë³‘í•© ë°ì´í„° í†µê³„
    print(f"\n[ë³‘í•© ë°ì´í„° (merged_influenza_data.csv)]")
    print(f"   â€¢ ì´ ë ˆì½”ë“œ ìˆ˜: {len(merged_df):,}")
    print(f"   â€¢ ì»¬ëŸ¼ ìˆ˜: {len(merged_df.columns)}")
    
    # ì—°ë„/ì£¼ì°¨ ë²”ìœ„
    print(f"\n[ë°ì´í„° ë²”ìœ„]")
    print(f"   â€¢ ì—°ë„: {merged_df['year'].min()} ~ {merged_df['year'].max()}")
    print(f"   â€¢ ì£¼ì°¨: {merged_df['week'].min()} ~ {merged_df['week'].max()}")
    
    # ì—°ë ¹ëŒ€ë³„ ë ˆì½”ë“œ ìˆ˜
    print(f"\n[ì—°ë ¹ëŒ€ë³„ ë ˆì½”ë“œ ìˆ˜]")
    age_counts = merged_df['age_group'].value_counts().sort_index()
    for age, count in age_counts.items():
        print(f"     - {age}: {count:,}í–‰")


def compare_year_week_coverage(before_data, merged_df):
    """
    ì—°ë„/ì£¼ì°¨ ì»¤ë²„ë¦¬ì§€ ë¹„êµ
    """
    print("\n" + "="*70)
    print("ğŸ“… ì—°ë„/ì£¼ì°¨ ì»¤ë²„ë¦¬ì§€ ë¹„êµ")
    print("="*70)
    
    # ì›ë³¸ ë°ì´í„°ì˜ ì—°ë„/ì£¼ì°¨ ì§‘í•©
    before_year_weeks = set()
    for dsid, df in before_data.items():
        if 'ì—°ë„' in df.columns and 'ì£¼ì°¨' in df.columns:
            for _, row in df.iterrows():
                before_year_weeks.add((int(row['ì—°ë„']), int(row['ì£¼ì°¨'])))
    
    # ë³‘í•© ë°ì´í„°ì˜ ì—°ë„/ì£¼ì°¨ ì§‘í•©
    merged_year_weeks = set()
    for _, row in merged_df.iterrows():
        merged_year_weeks.add((int(row['year']), int(row['week'])))
    
    print(f"\n[ì›ë³¸ ë°ì´í„°]")
    print(f"   â€¢ ê³ ìœ  (ì—°ë„, ì£¼ì°¨) ì¡°í•©: {len(before_year_weeks)}ê°œ")
    
    print(f"\n[ë³‘í•© ë°ì´í„°]")
    print(f"   â€¢ ê³ ìœ  (ì—°ë„, ì£¼ì°¨) ì¡°í•©: {len(merged_year_weeks)}ê°œ")
    
    # ëˆ„ë½ëœ ì—°ë„/ì£¼ì°¨
    missing = before_year_weeks - merged_year_weeks
    extra = merged_year_weeks - before_year_weeks
    
    if missing:
        print(f"\nâš ï¸  ì›ë³¸ì—ëŠ” ìˆì§€ë§Œ ë³‘í•©ì— ì—†ëŠ” (ì—°ë„, ì£¼ì°¨): {len(missing)}ê°œ")
        # ì²˜ìŒ 10ê°œë§Œ í‘œì‹œ
        for yw in sorted(missing)[:10]:
            print(f"      - {yw[0]}ë…„ {yw[1]}ì£¼")
        if len(missing) > 10:
            print(f"      ... ì™¸ {len(missing) - 10}ê°œ")
    else:
        print(f"\nâœ… ëª¨ë“  ì›ë³¸ ì—°ë„/ì£¼ì°¨ê°€ ë³‘í•© ë°ì´í„°ì— í¬í•¨ë¨")
    
    if extra:
        print(f"\nğŸ“Œ ë³‘í•©ì—ëŠ” ìˆì§€ë§Œ ì›ë³¸ì— ì—†ëŠ” (ì—°ë„, ì£¼ì°¨): {len(extra)}ê°œ")
        # ì´ê±´ ì •ìƒì ì¸ ê²½ìš°ê°€ ë§ìŒ (APIì—ì„œ ì¶”ê°€ ë°ì´í„°)


def compare_values_sample(before_data, merged_df, sample_size=20):
    """
    íŠ¹ì • ë°ì´í„°ì…‹ì˜ ê°’ ë¹„êµ (ìƒ˜í”Œ)
    """
    print("\n" + "="*70)
    print("ğŸ” ê°’ ë¹„êµ (ILI ë°ì´í„° ìƒ˜í”Œ)")
    print("="*70)
    
    # ds_0101 (ILI ë°ì´í„°)ë§Œ ë¹„êµ
    if 'ds_0101' not in before_data:
        print("   ds_0101 ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    before_ili = before_data['ds_0101'].copy()
    before_ili = before_ili.rename(columns={
        'ì—°ë„': 'year',
        'ì£¼ì°¨': 'week',
        'ì—°ë ¹ëŒ€': 'age_group',
        'ì˜ì‚¬í™˜ì ë¶„ìœ¨': 'ili_before'
    })
    
    # ìˆ«ì íƒ€ì…ìœ¼ë¡œ ë³€í™˜
    before_ili['year'] = before_ili['year'].astype(int)
    before_ili['week'] = before_ili['week'].astype(int)
    before_ili['ili_before'] = pd.to_numeric(before_ili['ili_before'], errors='coerce')
    
    # ë³‘í•© ë°ì´í„°ì—ì„œ ILI ì»¬ëŸ¼ ì¶”ì¶œ
    merged_ili = merged_df[['year', 'week', 'age_group', 'ili']].copy()
    merged_ili['ili'] = pd.to_numeric(merged_ili['ili'], errors='coerce')
    
    # ë³‘í•©í•˜ì—¬ ë¹„êµ
    comparison = before_ili.merge(
        merged_ili,
        on=['year', 'week', 'age_group'],
        how='inner',
        suffixes=('_before', '_merged')
    )
    
    print(f"\n   ë§¤ì¹­ëœ ë ˆì½”ë“œ ìˆ˜: {len(comparison):,}")
    
    # ì°¨ì´ ê³„ì‚°
    comparison['diff'] = abs(comparison['ili_before'] - comparison['ili'])
    
    # ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” ë ˆì½”ë“œ
    exact_match = (comparison['diff'] < 0.001) | (comparison['ili_before'].isna() & comparison['ili'].isna())
    exact_match_count = exact_match.sum()
    
    print(f"   ì •í™•íˆ ì¼ì¹˜: {exact_match_count:,} ({exact_match_count/len(comparison)*100:.1f}%)")
    
    # ì°¨ì´ê°€ ìˆëŠ” ë ˆì½”ë“œ ìƒ˜í”Œ
    mismatches = comparison[~exact_match].head(sample_size)
    if len(mismatches) > 0:
        print(f"\n   ì°¨ì´ê°€ ìˆëŠ” ë ˆì½”ë“œ ìƒ˜í”Œ (ì²˜ìŒ {min(len(mismatches), sample_size)}ê°œ):")
        print(mismatches[['year', 'week', 'age_group', 'ili_before', 'ili', 'diff']].to_string(index=False))
    else:
        print("\n   âœ… ëª¨ë“  ILI ê°’ì´ ì •í™•íˆ ì¼ì¹˜í•©ë‹ˆë‹¤!")


def compare_column_coverage(before_data, merged_df):
    """
    ì»¬ëŸ¼ë³„ ë°ì´í„° ì»¤ë²„ë¦¬ì§€ ë¹„êµ
    """
    print("\n" + "="*70)
    print("ğŸ“‹ ì»¬ëŸ¼ë³„ ë°ì´í„° ì»¤ë²„ë¦¬ì§€")
    print("="*70)
    
    columns_to_check = ['ili', 'detection_rate', 'hospitalization', 'vaccine_rate', 'emergency_patients']
    
    print(f"\n{'ì»¬ëŸ¼':<25} {'ì´ í–‰':<12} {'ê°’ ìˆìŒ':<12} {'ë¹„ìœ¨':<10}")
    print("-" * 60)
    
    for col in columns_to_check:
        if col in merged_df.columns:
            total = len(merged_df)
            non_null = merged_df[col].notna().sum()
            ratio = non_null / total * 100
            print(f"{col:<25} {total:<12,} {non_null:<12,} {ratio:.1f}%")


def validate_data(before_data, merged_df):
    """
    ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ ë° ì •ìƒ/ë¹„ì •ìƒ íŒë‹¨
    
    Returns:
        dict: ê²€ì¦ ê²°ê³¼
    """
    results = {
        'is_valid': True,
        'errors': [],
        'warnings': [],
        'stats': {}
    }
    
    # 1. ì—°ë„/ì£¼ì°¨ ì»¤ë²„ë¦¬ì§€ ê²€ì¦
    before_year_weeks = set()
    for dsid, df in before_data.items():
        if 'ì—°ë„' in df.columns and 'ì£¼ì°¨' in df.columns:
            for _, row in df.iterrows():
                before_year_weeks.add((int(row['ì—°ë„']), int(row['ì£¼ì°¨'])))
    
    merged_year_weeks = set(zip(merged_df['year'].astype(int), merged_df['week'].astype(int)))
    
    missing_weeks = before_year_weeks - merged_year_weeks
    if missing_weeks:
        results['errors'].append(f"ì›ë³¸ì— ìˆëŠ” {len(missing_weeks)}ê°œ (ì—°ë„,ì£¼ì°¨)ê°€ ë³‘í•© ë°ì´í„°ì— ëˆ„ë½ë¨")
        results['is_valid'] = False
    
    results['stats']['year_week_coverage'] = len(before_year_weeks - missing_weeks) / len(before_year_weeks) * 100 if before_year_weeks else 0
    
    # 2. ILI ê°’ ì¼ì¹˜ìœ¨ ê²€ì¦
    if 'ds_0101' in before_data:
        before_ili = before_data['ds_0101'].copy()
        before_ili = before_ili.rename(columns={
            'ì—°ë„': 'year', 'ì£¼ì°¨': 'week', 'ì—°ë ¹ëŒ€': 'age_group', 'ì˜ì‚¬í™˜ì ë¶„ìœ¨': 'ili_before'
        })
        before_ili['year'] = before_ili['year'].astype(int)
        before_ili['week'] = before_ili['week'].astype(int)
        before_ili['ili_before'] = pd.to_numeric(before_ili['ili_before'], errors='coerce')
        
        merged_ili = merged_df[['year', 'week', 'age_group', 'ili']].copy()
        merged_ili['ili'] = pd.to_numeric(merged_ili['ili'], errors='coerce')
        
        comparison = before_ili.merge(merged_ili, on=['year', 'week', 'age_group'], how='inner')
        
        if len(comparison) > 0:
            comparison['diff'] = abs(comparison['ili_before'] - comparison['ili'])
            exact_match = (comparison['diff'] < 0.001) | (comparison['ili_before'].isna() & comparison['ili'].isna())
            match_rate = exact_match.sum() / len(comparison) * 100
            
            results['stats']['ili_match_rate'] = match_rate
            results['stats']['ili_matched'] = exact_match.sum()
            results['stats']['ili_total'] = len(comparison)
            
            # ê°’ì´ ë‹¤ë¥¸ ë ˆì½”ë“œ (NaNìœ¼ë¡œ ë°”ë€ ê²½ìš° ì œì™¸í•˜ê³  ì‹¤ì œ ê°’ì´ ë‹¤ë¥¸ ê²½ìš°)
            value_diff = comparison[
                ~exact_match & 
                comparison['ili_before'].notna() & 
                comparison['ili'].notna()
            ]
            
            if len(value_diff) > 0:
                results['warnings'].append(f"ILI ê°’ì´ ë‹¤ë¥¸ ë ˆì½”ë“œ {len(value_diff)}ê°œ ë°œê²¬")
            
            # NaNìœ¼ë¡œ ë³€ê²½ëœ ë ˆì½”ë“œ
            nan_changed = comparison[
                ~exact_match & 
                comparison['ili_before'].notna() & 
                comparison['ili'].isna()
            ]
            if len(nan_changed) > 0:
                results['warnings'].append(f"ì›ë³¸ì—ëŠ” ê°’ì´ ìˆì§€ë§Œ ë³‘í•© ë°ì´í„°ì—ì„œ NaNì¸ ë ˆì½”ë“œ {len(nan_changed)}ê°œ")
            
            if match_rate < 95:
                results['errors'].append(f"ILI ê°’ ì¼ì¹˜ìœ¨ì´ 95% ë¯¸ë§Œ ({match_rate:.1f}%)")
                results['is_valid'] = False
    
    # 3. í•„ìˆ˜ ì»¬ëŸ¼ ë°ì´í„° ì¡´ì¬ ì—¬ë¶€
    required_cols = ['ili', 'detection_rate', 'hospitalization']
    for col in required_cols:
        if col in merged_df.columns:
            coverage = merged_df[col].notna().sum() / len(merged_df) * 100
            results['stats'][f'{col}_coverage'] = coverage
            if coverage < 30:
                results['warnings'].append(f"{col} ì»¬ëŸ¼ ë°ì´í„° ì»¤ë²„ë¦¬ì§€ê°€ 30% ë¯¸ë§Œ ({coverage:.1f}%)")
    
    return results


def print_final_verdict(results):
    """
    ìµœì¢… ê²€ì¦ ê²°ê³¼ ì¶œë ¥
    """
    print("\n" + "="*70)
    print("ğŸ ìµœì¢… ê²€ì¦ ê²°ê³¼")
    print("="*70)
    
    # í†µê³„ ì¶œë ¥
    stats = results['stats']
    print("\nğŸ“Š ê²€ì¦ í†µê³„:")
    if 'year_week_coverage' in stats:
        print(f"   â€¢ ì—°ë„/ì£¼ì°¨ ì»¤ë²„ë¦¬ì§€: {stats['year_week_coverage']:.1f}%")
    if 'ili_match_rate' in stats:
        print(f"   â€¢ ILI ê°’ ì¼ì¹˜ìœ¨: {stats['ili_match_rate']:.1f}% ({stats['ili_matched']:,}/{stats['ili_total']:,})")
    for col in ['ili', 'detection_rate', 'hospitalization', 'vaccine_rate', 'emergency_patients']:
        key = f'{col}_coverage'
        if key in stats:
            print(f"   â€¢ {col} ì»¤ë²„ë¦¬ì§€: {stats[key]:.1f}%")
    
    # ê²½ê³  ì¶œë ¥
    if results['warnings']:
        print(f"\nâš ï¸  ê²½ê³  ({len(results['warnings'])}ê±´):")
        for warning in results['warnings']:
            print(f"   â€¢ {warning}")
    
    # ì˜¤ë¥˜ ì¶œë ¥
    if results['errors']:
        print(f"\nâŒ ì˜¤ë¥˜ ({len(results['errors'])}ê±´):")
        for error in results['errors']:
            print(f"   â€¢ {error}")
    
    # ìµœì¢… íŒì •
    print("\n" + "-"*70)
    if results['is_valid']:
        if results['warnings']:
            print("ğŸ“‹ íŒì •: âœ… ì •ìƒ (ê²½ê³  ìˆìŒ)")
            print("   ë°ì´í„° ë³‘í•©ì´ ì •ìƒì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìœ¼ë‚˜, ì¼ë¶€ ê²½ê³  ì‚¬í•­ì´ ìˆìŠµë‹ˆë‹¤.")
        else:
            print("ğŸ“‹ íŒì •: âœ… ì •ìƒ")
            print("   ë°ì´í„° ë³‘í•©ì´ ì™„ë²½í•˜ê²Œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("ğŸ“‹ íŒì •: âŒ ë¹„ì •ìƒ")
        print("   ë°ì´í„° ë³‘í•©ì— ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì˜¤ë¥˜ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.")
    print("-"*70)
    
    return results['is_valid']


def main():
    print("="*70)
    print("ğŸ“Š data/before vs merged_influenza_data.csv ë¹„êµ")
    print("="*70)
    
    # ë°ì´í„° ë¡œë“œ
    before_data = load_before_data('data/before')
    merged_df = load_merged_data('merged_influenza_data.csv')
    
    if not before_data or merged_df is None:
        print("\nâŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨")
        print("\n" + "-"*70)
        print("ğŸ“‹ íŒì •: âŒ ë¹„ì •ìƒ")
        print("   ë°ì´í„° íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("-"*70)
        return False
    
    # ë¹„êµ ìˆ˜í–‰
    compare_statistics(before_data, merged_df)
    compare_year_week_coverage(before_data, merged_df)
    compare_values_sample(before_data, merged_df)
    compare_column_coverage(before_data, merged_df)
    
    # ê²€ì¦ ë° ìµœì¢… íŒì •
    results = validate_data(before_data, merged_df)
    is_valid = print_final_verdict(results)
    
    print("\n" + "="*70)
    print("âœ… ë¹„êµ ì™„ë£Œ!")
    print("="*70)
    
    return is_valid


if __name__ == "__main__":
    import sys
    is_valid = main()
    sys.exit(0 if is_valid else 1)
